{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "print(rpy2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "# import R's \"base\" package\n",
    "base = importr('base')\n",
    "\n",
    "# import R's \"utils\" package\n",
    "utils = importr('utils')\n",
    "\n",
    "# import rpy2's package module\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "# import R's utility package\n",
    "utils = rpackages.importr('utils')\n",
    "\n",
    "# select a mirror for R packages\n",
    "utils.chooseCRANmirror(ind=1) # select the first mirror in the list\n",
    "\n",
    "packnames = ('ggplot2', 'spam64')\n",
    "\n",
    "# R vector of strings\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "# Selectively install what needs to be install.\n",
    "# We are fancy, just because we can.\n",
    "names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]\n",
    "if len(names_to_install) > 0:\n",
    "    utils.install_packages(StrVector(names_to_install))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31313e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for writing out surface ply file with colormap created by matplotlib, e.g., to be imported into Blender\n",
    "\n",
    "def write_plyRGB(filename, vertices, faces, colorsR,colorsG,colorsB,comment=None):\n",
    "    import pandas as pd\n",
    "    print(\"writing ply format\")\n",
    "    # infer number of vertices and faces\n",
    "    number_vertices = vertices.shape[0]\n",
    "    number_faces = faces.shape[0]\n",
    "    # make header dataframe\n",
    "    header = ['ply',\n",
    "            'format ascii 1.0',\n",
    "            'comment %s' % comment,\n",
    "            'element vertex %i' % number_vertices,\n",
    "            'property float x',\n",
    "            'property float y',\n",
    "            'property float z',\n",
    "            'property uchar red',\n",
    "            'property uchar green',\n",
    "            'property uchar blue',\n",
    "            'element face %i' % number_faces,\n",
    "            'property list uchar int vertex_indices',\n",
    "            'end_header'\n",
    "             ]\n",
    "    header_df = pd.DataFrame(header)\n",
    "    # make dataframe from vertices\n",
    "    vertex_df = pd.DataFrame(vertices/50)\n",
    "    #colors_df = pd.DataFrame(np.tile(np.round(colors/7*255), (3,1)).T)\n",
    "    ColorsR_df=pd.DataFrame(colorsR)\n",
    "    ColorsG_df=pd.DataFrame(colorsG)\n",
    "    ColorsB_df=pd.DataFrame(colorsB)\n",
    "    colorsConcat = pd.concat([ColorsR_df,ColorsG_df,ColorsB_df], axis=1)\n",
    "    colors_df=pd.DataFrame(colorsConcat)\n",
    "    colors_df=colorsConcat.astype(int)\n",
    "    df_concat = pd.concat([vertex_df, colors_df], axis=1)\n",
    "    # make dataframe from faces, adding first row of 3s (indicating triangles)\n",
    "    triangles = np.reshape(3 * (np.ones(number_faces)), (number_faces, 1))\n",
    "    triangles = triangles.astype(int)\n",
    "    faces = faces.astype(int)\n",
    "    faces_df = pd.DataFrame(np.concatenate((triangles, faces), axis=1))\n",
    "    # write dfs to csv\n",
    "    header_df.to_csv(filename, header=None, index=False)\n",
    "    with open(filename, 'a') as f:\n",
    "        df_concat.to_csv(f, header=False, index=False,\n",
    "                         float_format='%.3f', sep=' ')\n",
    "    with open(filename, 'a') as f:\n",
    "        faces_df.to_csv(f, header=False, index=False,\n",
    "                        float_format='%.0f', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to read cifti data into python. \n",
    "\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def surf_data_from_cifti(data, axis, surf_name): \n",
    "    assert isinstance(axis, nb.cifti2.BrainModelAxis)\n",
    "    for name, data_indices, model in axis.iter_structures():  # Iterates over volumetric and surface structures\n",
    "        if name == surf_name:                                 # Just looking for a surface\n",
    "            data = data.T[data_indices]                       # Assume brainmodels axis is last, move it to front\n",
    "            vtx_indices = model.vertex                        # Generally 1-N, except medial wall vertices\n",
    "            surf_data = np.zeros((vtx_indices.max() + 1,) + data.shape[1:], dtype=data.dtype)\n",
    "            surf_data[vtx_indices] = data\n",
    "            return surf_data\n",
    "    raise ValueError(f\"No structure named {surf_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load surface Midnight Scan Club derivates data downloaded from openneuro website\n",
    "\n",
    "import glob\n",
    "\n",
    "left_brain=np.zeros([32492,10,3])\n",
    "\n",
    "# Loop through the file list and read each file\n",
    "dir_path='MSCderivatives/surface_pipeline/'\n",
    "for sub in range(10):\n",
    "\n",
    "    file_pattern = 'sub-MSC' + str(sub+1).zfill(2) + '/task_contrasts_cifti/*/' + '*fsLR_smooth2.55.dscalar.nii'\n",
    "    #file_pattern = 'sub-MSC' + str(sub+1).zfill(2) + '/task_contrasts_cifti/*/' + '*fsLR.dscalar.nii'\n",
    "    \n",
    "    file_list = glob.glob(f\"{dir_path}/{file_pattern}\")\n",
    "\n",
    "    \n",
    "    for i, fileName in enumerate(file_list):\n",
    "        print(fileName)\n",
    "        cifti = nb.load(fileName)\n",
    "        cifti_data = cifti.get_fdata(dtype=np.float32)\n",
    "        cifti_hdr = cifti.header\n",
    "        nifti_hdr = cifti.nifti_header\n",
    "        axes = [cifti_hdr.get_axis(i) for i in range(cifti.ndim)]\n",
    "        \n",
    "        \n",
    "        left_brain[:,sub,i]=surf_data_from_cifti(cifti_data, axes[1], 'CIFTI_STRUCTURE_CORTEX_LEFT')[:,0]*-1 # Remove -1 to look at predict task negative\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae5b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check of projection onto surface and load 3D coordinates and faces of FSLR32k MSM surface for visualisation\n",
    "# Surface downloaded from HCP group data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gifti_img_Midthickness = nb.load('S900.L.midthickness_MSMAll.32k_fs_LR.surf.gii')\n",
    "xyz_points_Mid=gifti_img_Midthickness.darrays[0].data\n",
    "azim=180\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "print(left_brain.shape)\n",
    "\n",
    "p=ax.scatter(xyz_points_Mid[:,0],xyz_points_Mid[:,1],xyz_points_Mid[:,2],c=np.where(left_brain[:,1,1]>1,left_brain[:,1,1],0),s=5,cmap='bwr_r',vmin=-2,vmax=2)\n",
    "ax.view_init(elev=10., azim=azim)\n",
    "fig.colorbar(p,ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e86e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from R3 (euclidean xyz) to S2 (spherical) coordinates and load FSLR32k spherical projection coordinates\n",
    "# Surface downloaded from HCP group data\n",
    "\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    " \n",
    "gifti_img_BaseBrain = nb.load('S900.L.sphere.32k_fs_LR.surf.gii')\n",
    "\n",
    "xyz_points=gifti_img_BaseBrain.darrays[0].data\n",
    "\n",
    "\n",
    "def appendSpherical_np(xyz):\n",
    "    ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "    \n",
    "    xy = xyz[:,0]**2 + xyz[:,1]**2\n",
    "    ptsnew[:,3] = np.sqrt(xy + xyz[:,2]**2)\n",
    "    ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy)) # for elevation angle defined from XY-plane up\n",
    "    ptsnew[:,5] = np.arctan2(xyz[:,1], xyz[:,0])\n",
    "    return ptsnew\n",
    "\n",
    "ptsnew=appendSpherical_np(xyz_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run lattice kriging on lowest 25% of vertices\n",
    "\n",
    "import numpy as np\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import FloatVector\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "pandas2ri.activate()\n",
    "LK = importr('LatticeKrig')\n",
    "\n",
    "\n",
    "LKPred=np.zeros(left_brain.shape)\n",
    "\n",
    "for i in range(left_brain.shape[1]):\n",
    "    for j in range(left_brain.shape[2]):\n",
    "\n",
    "        NotZero=np.abs(left_brain[:,i,j])>0\n",
    "        threshUpper= np.percentile(left_brain[NotZero,i,j], 75, axis=0)\n",
    "        threshLower= np.percentile(left_brain[NotZero,i,j], 25, axis=0)\n",
    "        \n",
    "\n",
    "\n",
    "        print(threshUpper)\n",
    "\n",
    "        pos_index=left_brain[:,i,j]>threshUpper\n",
    "        #neg_index=left_brain[:,task]<-3\n",
    "\n",
    "        X_temp=np.degrees(ptsnew[pos_index,4])\n",
    "\n",
    "        X1=FloatVector(X_temp[:])\n",
    "\n",
    "        X_temp=np.degrees(ptsnew[pos_index,5])\n",
    "        X2=FloatVector(X_temp[:])\n",
    "        Y_temp=left_brain[pos_index,i,j]\n",
    "        Y=FloatVector(Y_temp[:])\n",
    "\n",
    "\n",
    "        df = pd.DataFrame({'X1': X2, 'X2': X1})\n",
    "\n",
    "        r_dataframe = pandas2ri.py2rpy(df)\n",
    "\n",
    "\n",
    "        alpha=FloatVector(np.power([1,0.5,0.1],2))\n",
    "\n",
    "        LKinfo=LK.LKrigSetup(r_dataframe,startingLevel=3,nlevel=3,a_wght=1.01,alpha=alpha,LKGeometry=\"LKSphere\",Radius=100) \n",
    "\n",
    "        LKOutput=LK.LatticeKrig(r_dataframe,Y,LKinfo=LKinfo)\n",
    "\n",
    "        X1_all=FloatVector(np.degrees(ptsnew[:,4]))\n",
    "        X2_all=FloatVector(np.degrees(ptsnew[:,5]))\n",
    "        Y_all=FloatVector(left_brain[:,i,j])\n",
    "\n",
    "\n",
    "        df_all = pd.DataFrame({'X1': X2_all, 'X2': X1_all})\n",
    "\n",
    "        r_dataframe_all = pandas2ri.py2rpy(df_all)\n",
    "        LKPred[:,i,j]=r.predict(LKOutput,r_dataframe_all).ravel()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b3eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out .ply surfaces of interpolated data for each task for each participant.\n",
    "import  matplotlib.cm\n",
    "cmap = matplotlib.cm.get_cmap('coolwarm_r')\n",
    "vertices=gifti_img_Midthickness.darrays[0].data\n",
    "faces=gifti_img_Midthickness.darrays[1].data\n",
    "for task in range(3):\n",
    "    for sub in range(10):\n",
    "    \n",
    "        NotZero=np.abs(left_brain[:,sub,task])>0\n",
    "        threshUpper= np.percentile(left_brain[NotZero,sub,task], 75, axis=0)\n",
    "\n",
    "        colors=left_brain[:,sub,task]\n",
    "        norm = matplotlib.colors.Normalize(vmin=-2, vmax=2)\n",
    "        CMap=cmap(norm(colors))*255\n",
    "        PlyFileName='MSCActivitySmoothed' + str(task) +'_sub_' + str(sub) + '.ply'\n",
    "        write_plyRGB(PlyFileName,vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    "\n",
    "        colors=np.zeros(left_brain[:, sub,task].shape)\n",
    "        colors[left_brain[:,sub,task]>threshUpper]=left_brain[left_brain[:,sub,task]>threshUpper,sub,task]\n",
    "        norm = matplotlib.colors.Normalize(vmin=-2, vmax=2)\n",
    "        CMap=cmap(norm(colors))*255\n",
    "        PlyFileName='MSCThreshSmoothed' + str(task) +'_sub_' + str(sub) + '.ply'\n",
    "        write_plyRGB(PlyFileName,vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    "\n",
    "        colors=np.zeros(left_brain[:, sub,task].shape)\n",
    "        colors[NotZero]=LKPred[NotZero,sub,task]\n",
    "        NotZero\n",
    "        norm = matplotlib.colors.Normalize(vmin=-2, vmax=2)\n",
    "        CMap=cmap(norm(colors))*255\n",
    "        PlyFileName='MSCprojectedSmoothed' + str(task) +'_sub_' + str(sub) + '.ply'\n",
    "        write_plyRGB(PlyFileName,vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd117f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out .ply files for real and interpolated maps averaged over the group.\n",
    "for task in range(3):\n",
    "    \n",
    "    colors=left_brain.mean(axis=1)[:,task]\n",
    "    norm = matplotlib.colors.Normalize(vmin=-2, vmax=2)\n",
    "    CMap=cmap(norm(colors))*255\n",
    "    PlyFileName='MSCSmoothGroupAvActivity' + str(task) + '.ply'\n",
    "    write_plyRGB(PlyFileName,vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    "\n",
    "    colors=np.zeros(left_brain[:, 0,task].shape)\n",
    "    colors[NotZero]=LKPred.mean(axis=1)[NotZero,task]\n",
    "    NotZero\n",
    "    norm = matplotlib.colors.Normalize(vmin=-2, vmax=2)\n",
    "    CMap=cmap(norm(colors))*255\n",
    "    PlyFileName='MSCSmoothGroupAvProjected' + str(task) + '.ply'\n",
    "    write_plyRGB(PlyFileName,vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0d40d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualise some real and predicted within jupyter notebook as a sanity check in jupyter notebook \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "gifti_img_Midthickness = nb.load('/Users/robleech/Dropbox/HCP_S900_GroupAvg_v1/S900.L.midthickness_MSMAll.32k_fs_LR.surf.gii')\n",
    "xyz_points_Mid=gifti_img_Midthickness.darrays[0].data\n",
    "azim=180\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "p=ax.scatter(xyz_points_Mid[:,0],xyz_points_Mid[:,1],xyz_points_Mid[:,2],c=left_brain[:,3,2],s=3,cmap='bwr_r',vmin=-5,vmax=5)\n",
    "ax.view_init(elev=10., azim=azim)\n",
    "fig.colorbar(p,ax=ax)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "p=ax.scatter(xyz_points_Mid[:,0],xyz_points_Mid[:,1],xyz_points_Mid[:,2],c=LKPred[:,3,2],s=3,cmap='bwr_r',vmin=-5,vmax=5)\n",
    "ax.view_init(elev=10., azim=azim)\n",
    "fig.colorbar(p,ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c01895",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# With latticeKrig predict task activity in conjunction mask from each pair of tasks.\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import FloatVector\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "tasks=np.asarray([0,1,2])\n",
    "\n",
    "LKPredAllTasks=np.zeros([10,tasks.shape[0],tasks.shape[0]])\n",
    "LKPredAllTasksAlt=np.zeros([10,tasks.shape[0],tasks.shape[0]])\n",
    "LKPredAllTasksTNRestrict=np.zeros([10,tasks.shape[0],tasks.shape[0]])\n",
    "LKPredAllTasksTNRestrictAlt=np.zeros([10,tasks.shape[0],tasks.shape[0]])\n",
    "\n",
    "LK = importr('LatticeKrig')\n",
    "for i in range(10):\n",
    "    print('subject' + str(i))\n",
    "    for u in range(tasks.shape[0]):\n",
    "        print(u)\n",
    "        for v in range(tasks.shape[0]):\n",
    "            print(v)\n",
    "            #print(v)\n",
    "            #if u !=v: \n",
    "            tasksCompare=np.array([u,v])\n",
    "            NotZero1=np.abs(left_brain[:,i,u])>0\n",
    "            NotZero2=np.abs(left_brain[:,i,v])>0\n",
    "            threshTask1= np.percentile(left_brain[NotZero1,i,u], 75, axis=0)\n",
    "            threshTask2= np.percentile(left_brain[NotZero2,i,v], 75, axis=0)\n",
    "\n",
    "            pos_index=np.logical_and(left_brain[:,i,u]>threshTask1,left_brain[:,i,v]>threshTask2)\n",
    "            neg_index=np.logical_not(left_brain[:,i,u]>threshTask1,left_brain[:,i,v]>threshTask2)\n",
    "            #neg_index=np.logical_and(left_brain[:,tasksCompare[0]]<0,left_brain[:,tasksCompare[1]]<0)\n",
    "\n",
    "            #pos_index=np.logical_and(left_brain[:,tasksCompare[0]]>10,left_brain[:,tasksCompare[1]]>10)\n",
    "            #neg_index=np.logical_not(left_brain[:,tasksCompare[0]]>10,left_brain[:,tasksCompare[1]]>10)\n",
    "\n",
    "            task=u\n",
    "            \n",
    "            X_temp=np.degrees(ptsnew[pos_index,4])\n",
    "\n",
    "            X1=FloatVector(X_temp[:])\n",
    "\n",
    "            X_temp=np.degrees(ptsnew[pos_index,5])\n",
    "            X2=FloatVector(X_temp[:])\n",
    "            Y_temp=left_brain[pos_index,i,task]\n",
    "            Y=FloatVector(Y_temp[:])\n",
    "\n",
    "            df = pd.DataFrame({'X1': X2, 'X2': X1})\n",
    "\n",
    "            r_dataframe = pandas2ri.py2rpy(df)\n",
    "\n",
    "            alpha=FloatVector(np.power([1,0.5,0.1],2))\n",
    "\n",
    "            LKinfo=LK.LKrigSetup(r_dataframe,startingLevel=3,nlevel=3,a_wght=1.01,alpha=alpha,LKGeometry=\"LKSphere\",Radius=100) \n",
    "\n",
    "            LKOutput=LK.LatticeKrig(r_dataframe,Y,LKinfo=LKinfo)\n",
    "\n",
    "            X1_all=FloatVector(np.degrees(ptsnew[:,4]))\n",
    "            X2_all=FloatVector(np.degrees(ptsnew[:,5]))\n",
    "            Y_all=FloatVector(left_brain[:,i,task])\n",
    "\n",
    "\n",
    "            df_all = pd.DataFrame({'X1': X2_all, 'X2': X1_all})\n",
    "\n",
    "            r_dataframe_all = pandas2ri.py2rpy(df_all)\n",
    "            tempPredict=r.predict(LKOutput,r_dataframe_all).ravel()\n",
    "\n",
    "            LKPredAllTasks[i,u,v]=stats.spearmanr(tempPredict[neg_index],left_brain[neg_index,i,u])[0]\n",
    "            LKPredAllTasksAlt[i,u,v]=stats.spearmanr(tempPredict[neg_index],left_brain[neg_index,i,v])[0]\n",
    "            LKPredAllTasksTNRestrict[i,u,v]=stats.spearmanr(tempPredict[left_brain[:,i,u]<0],left_brain[left_brain[:,i,u]<0,i,u])[0]\n",
    "            LKPredAllTasksTNRestrictAlt[i,u,v]=stats.spearmanr(tempPredict[left_brain[:,i,u]<0],left_brain[left_brain[:,i,u]<0,i,v])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14d50b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display across task similarity for group\n",
    "print(LKPredAllTasks.shape)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh((LKPredAllTasks.mean(axis=0)-LKPredAllTasksAlt.mean(axis=0)), edgecolors='k', linestyle='-',linewidth=1,vmin=-0.5,vmax=0.5,cmap='bwr')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig(\"MSCIntersectionPermuteSmooth.png\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b310868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display across task similarity for individuals\n",
    "\n",
    "for i in range(10):\n",
    "    #plt.imshow(LKPredAllTasks[i,:,:]-LKPredAllTasksAlt[i,:,:],cmap='bwr',vmin=-1,vmax=1)\n",
    "   \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    #plt.imshow(LKPredAllTasks-LKPredAllTasksAlt,vmin=-0.5,vmax=0.5,cmap='bwr')\n",
    "    plt.pcolormesh(LKPredAllTasks[i,:,:]-LKPredAllTasksAlt[i,:,:], edgecolors='k', linestyle='-',linewidth=1,vmin=-0.5,vmax=0.5,cmap='bwr')\n",
    "    #plt.pcolormesh(LKPredAllTasksTNRestrict[i,:,:]-LKPredAllTasksTNRestrictAlt[i,:,:], edgecolors='k', linestyle='-',linewidth=1,vmin=-0.5,vmax=0.5,cmap='bwr')\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.savefig('MSCSmoothIntersectionPermute_Sub' + str(i) + '.png', bbox_inches='tight')\n",
    "    #plt.imshow(LKPredAllTasksTNRestrict-LKPredAllTasksTNRestrictAlt,vmin=-0.5,vmax=0.5,cmap='bwr')\n",
    "    #plt.imshow(LKPredAllTasksMinDist-LKPredAllTasksAltMinDist,vmin=-0.5,vmax=0.5,cmap='bwr')\n",
    "    #plt.colorbar()\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
