{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure is the same as in LatticeAllHCPTaskPredNegative except that the task maps have been inverted (see code block 5, line 18)\n",
    "\n",
    "import rpy2\n",
    "print(rpy2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "# import R's \"base\" package\n",
    "base = importr('base')\n",
    "\n",
    "# import R's \"utils\" package\n",
    "utils = importr('utils')\n",
    "\n",
    "# import rpy2's package module\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "# import R's utility package\n",
    "utils = rpackages.importr('utils')\n",
    "\n",
    "# select a mirror for R packages\n",
    "utils.chooseCRANmirror(ind=1) # select the first mirror in the list\n",
    "\n",
    "packnames = ('ggplot2', 'spam64')\n",
    "\n",
    "# R vector of strings\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "# Selectively install what needs to be install.\n",
    "# We are fancy, just because we can.\n",
    "names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]\n",
    "if len(names_to_install) > 0:\n",
    "    utils.install_packages(StrVector(names_to_install))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98669eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    " \n",
    "# cifti code based on Christopher J Markiewicz https://nbviewer.jupyter.org/github/neurohackademy/nh2020-curriculum/blob/master/we-nibabel-markiewicz/NiBabel.ipynb\n",
    "# load cifti file containing the vertexwise values, in this case myelin map from the HCP\n",
    "cifti = nb.load('HCP_S900_787_tfMRI_ALLTASKS_level3_zstat1_hp200_s2_MSMSulc.dscalar.nii')\n",
    "cifti_data = cifti.get_fdata(dtype=np.float32)\n",
    "cifti_hdr = cifti.header\n",
    "nifti_hdr = cifti.nifti_header\n",
    "\n",
    "axes = [cifti_hdr.get_axis(i) for i in range(cifti.ndim)]\n",
    "\n",
    "def surf_data_from_cifti(data, axis, surf_name): \n",
    "    assert isinstance(axis, nb.cifti2.BrainModelAxis)\n",
    "    for name, data_indices, model in axis.iter_structures():  # Iterates over volumetric and surface structures\n",
    "        if name == surf_name:                                 # Just looking for a surface\n",
    "            data = data.T[data_indices]                       # Assume brainmodels axis is last, move it to front\n",
    "            vtx_indices = model.vertex                        # Generally 1-N, except medial wall vertices\n",
    "            surf_data = np.zeros((vtx_indices.max() + 1,) + data.shape[1:], dtype=data.dtype)\n",
    "            surf_data[vtx_indices] = data\n",
    "            return surf_data\n",
    "    raise ValueError(f\"No structure named {surf_name}\")\n",
    "\n",
    "left_brain=surf_data_from_cifti(cifti_data, axes[1], 'CIFTI_STRUCTURE_CORTEX_LEFT')\n",
    "\n",
    "#load gifti surface that is the same resolution/underlying mesh etc as the cifti\n",
    "gifti_img_BaseBrain = nb.load('S900.L.sphere.32k_fs_LR.surf.gii')\n",
    "\n",
    "\n",
    "\n",
    "xyz_points=gifti_img_BaseBrain.darrays[0].data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def appendSpherical_np(xyz):\n",
    "    ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "    \n",
    "    xy = xyz[:,0]**2 + xyz[:,1]**2\n",
    "    ptsnew[:,3] = np.sqrt(xy + xyz[:,2]**2)\n",
    "    #ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2]) # for elevation angle defined from Z-axis down\n",
    "    ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy)) # for elevation angle defined from XY-plane up\n",
    "    ptsnew[:,5] = np.arctan2(xyz[:,1], xyz[:,0])\n",
    "    return ptsnew\n",
    "\n",
    "ptsnew=appendSpherical_np(xyz_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import FloatVector\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "\n",
    "pandas2ri.activate()\n",
    "LK = importr('LatticeKrig')\n",
    "cifti = nb.load('HCP_S900_787_tfMRI_ALLTASKS_level3_zstat1_hp200_s2_MSMSulc.dscalar.nii')\n",
    "cifti_data = cifti.get_fdata(dtype=np.float32)\n",
    "cifti_hdr = cifti.header\n",
    "nifti_hdr = cifti.nifti_header\n",
    "\n",
    "axes = [cifti_hdr.get_axis(i) for i in range(cifti.ndim)]\n",
    "left_brain=surf_data_from_cifti(cifti_data, axes[1], 'CIFTI_STRUCTURE_CORTEX_LEFT')\n",
    "left_brain=left_brain*-1\n",
    "taskNames=np.loadtxt('TaskNames.txt',dtype=str,delimiter=',')\n",
    "tasks=np.asarray([9,31,42,62,69,74,80])\n",
    "\n",
    "LKPredAllTasks=np.zeros([ptsnew.shape[0],tasks.shape[0]])\n",
    "AllThresh=np.zeros([7])\n",
    "count=0\n",
    "for i in range(tasks.shape[0]):\n",
    "\n",
    "        task=tasks[i]\n",
    "        threshUpper= np.percentile(left_brain[:,task], 75, axis=0)\n",
    "        threshLower= np.percentile(left_brain[:,task], 25, axis=0)\n",
    "\n",
    "        AllThresh[i]=threshUpper\n",
    "\n",
    "        pos_index=left_brain[:,task]>threshUpper\n",
    "        neg_index=left_brain[:,task]<threshLower\n",
    "\n",
    "        X_temp=np.degrees(ptsnew[pos_index,4])\n",
    "\n",
    "        X1=FloatVector(X_temp[:])\n",
    "\n",
    "        X_temp=np.degrees(ptsnew[pos_index,5])\n",
    "\n",
    "        X2=FloatVector(X_temp[:])\n",
    "        Y_temp=left_brain[pos_index,task]\n",
    "\n",
    "        Y=FloatVector(Y_temp[:])\n",
    "\n",
    "\n",
    "        df = pd.DataFrame({'X1': X2, 'X2': X1})\n",
    "\n",
    "        r_dataframe = pandas2ri.py2rpy(df)\n",
    "        alpha=FloatVector(np.power([1,0.5,0.1],2))\n",
    "\n",
    "        LKinfo=LK.LKrigSetup(r_dataframe,startingLevel=3,nlevel=3,a_wght=1.01,alpha=alpha,LKGeometry=\"LKSphere\",Radius=100) \n",
    "\n",
    "        LKOutput=LK.LatticeKrig(r_dataframe,Y,LKinfo=LKinfo)\n",
    "\n",
    "        X1_all=FloatVector(np.degrees(ptsnew[:,4]))\n",
    "        X2_all=FloatVector(np.degrees(ptsnew[:,5]))\n",
    "        Y_all=FloatVector(left_brain[:,task])\n",
    "\n",
    "\n",
    "        df_all = pd.DataFrame({'X1': X2_all, 'X2': X1_all})\n",
    "\n",
    "        r_dataframe_all = pandas2ri.py2rpy(df_all)\n",
    "        LKPredAllTasks[:,count]=r.predict(LKOutput,r_dataframe_all).ravel()\n",
    "        count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0d40d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gifti_img_Midthickness = nb.load('S900.L.midthickness_MSMAll.32k_fs_LR.surf.gii')\n",
    "xyz_points_Mid=gifti_img_Midthickness.darrays[0].data\n",
    "azim=0\n",
    "\n",
    "\n",
    "TPProj=(LKPredAllTasks<0).mean(axis=1)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "p=ax.scatter(xyz_points_Mid[np.abs(left_brain[:,0])>0,0],xyz_points_Mid[np.abs(left_brain[:,0])>0,1],xyz_points_Mid[np.abs(left_brain[:,0])>0,2],c=TPProj[np.abs(left_brain[:,0])>0],s=3,cmap='Reds',vmin=0,vmax=1)\n",
    "ax.view_init(elev=10., azim=azim)\n",
    "fig.colorbar(p,ax=ax)\n",
    "\n",
    "TPReal=(left_brain[:,tasks]<0).mean(axis=1)\n",
    "TPReal_NoMedialWall=np.where(TPReal==0,0,TPReal)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "p=ax.scatter(xyz_points_Mid[np.abs(left_brain[:,0])>0,0],xyz_points_Mid[np.abs(left_brain[:,0])>0,1],xyz_points_Mid[np.abs(left_brain[:,0])>0,2],c=TPReal[np.abs(left_brain[:,0])>0],s=3,cmap='Reds',vmin=0,vmax=1)\n",
    "ax.view_init(elev=10., azim=azim)\n",
    "fig.colorbar(p,ax=ax)\n",
    "\n",
    "TPProj_NoMedialWall=np.where(TPReal==0,0,TPProj)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "p=ax.scatter(xyz_points_Mid[np.abs(left_brain[:,0])>0,0],xyz_points_Mid[np.abs(left_brain[:,0])>0,1],xyz_points_Mid[np.abs(left_brain[:,0])>0,2],c=TPReal[np.abs(left_brain[:,0])>0]-TPProj[np.abs(left_brain[:,0])>0],s=3,cmap='Reds',vmin=0,vmax=1)\n",
    "ax.view_init(elev=10., azim=azim)\n",
    "fig.colorbar(p,ax=ax)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67130dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPProj_NoMedialWall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a528d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d81fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "az=0\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "p=ax.scatter(xyz_points_Mid[:,0],xyz_points_Mid[:,1],xyz_points_Mid[:,2],c=fcgradient[:,0],s=3)\n",
    "\n",
    "ax.view_init(elev=10., azim=az)\n",
    "fig.colorbar(p,ax=ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "p=ax.scatter(xyz_points_Mid[:,0],xyz_points_Mid[:,1],xyz_points_Mid[:,2],c=fcgradient[:,1],s=3)\n",
    "\n",
    "ax.view_init(elev=10., azim=az)\n",
    "fig.colorbar(p,ax=ax)\n",
    "plt.show()\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "p=ax.scatter(xyz_points_Mid[:,0],xyz_points_Mid[:,1],xyz_points_Mid[:,2],c=fcgradient[:,2],s=3)\n",
    "\n",
    "ax.view_init(elev=10., azim=az)\n",
    "fig.colorbar(p,ax=ax)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "p=ax.scatter(xyz_points_Mid[:,0],xyz_points_Mid[:,1],xyz_points_Mid[:,2],c=TPProj_NoMedialWall,s=3)\n",
    "ax.view_init(elev=10., azim=az)\n",
    "fig.colorbar(p,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806a490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c01895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "azim=180\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "p=ax.scatter(xyz_points_Mid[:,0],xyz_points_Mid[:,1],xyz_points_Mid[:,2],c=TPProj_NoMedialWall,s=3,cmap='Reds',vmin=0,vmax=1)\n",
    "ax.view_init(elev=10., azim=azim)\n",
    "fig.colorbar(p,ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14d50b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TaskProjCompareTasks=np.zeros([7,7])\n",
    "\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "num_tasks=tasks.shape[0]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(5* 2 , 5))\n",
    "\n",
    "for taskID, task in enumerate(tasks):\n",
    "    threshUpper= np.percentile(left_brain[:,task], 75, axis=0)\n",
    "    \n",
    "    pos_index=left_brain[:,task]>threshUpper\n",
    "    neg_index=left_brain[:,task]<threshUpper\n",
    "\n",
    "    for taskID2, task2 in enumerate(tasks):\n",
    "        predtask=LKPredAllTasks[neg_index, taskID]*-1\n",
    "        task_data = left_brain[neg_index, task2]*-1\n",
    "        TaskProjCompareTasks[taskID,taskID2]=stats.spearmanr(predtask,task_data)[0]\n",
    "        \n",
    "TaskProjCompareTasks=TaskProjCompareTasks[::-1,:]\n",
    "axes[0].pcolormesh((TaskProjCompareTasks), edgecolors='k', linestyle=':',linewidth=2,vmin=-1,vmax=1,cmap='bwr')\n",
    "\n",
    "axes[0].tick_params(left = False, right = False , labelleft = False , \n",
    "                labelbottom = False, bottom = False)\n",
    "\n",
    "\n",
    "\n",
    "TaskProjCompareTasks=np.zeros([7,7])\n",
    "\n",
    "#import seaborn as sns\n",
    "from scipy import stats\n",
    "num_tasks=tasks.shape[0]\n",
    "\n",
    "count=0\n",
    "for taskID, task in enumerate(tasks):\n",
    "    threshUpper= np.percentile(left_brain[:,task], 75, axis=0)\n",
    "    \n",
    "\n",
    "    pos_index=left_brain[:,task]>threshUpper\n",
    "    neg_index=left_brain[:,task]<0\n",
    "\n",
    "    for taskID2, task2 in enumerate(tasks):\n",
    "        predtask=LKPredAllTasks[neg_index, taskID]*-1\n",
    "        task_data = left_brain[neg_index, task2]*-1\n",
    "        TaskProjCompareTasks[taskID,taskID2]=stats.spearmanr(predtask,task_data)[0]\n",
    "        \n",
    "TaskProjCompareTasks=TaskProjCompareTasks[::-1,:]\n",
    "axes[1].pcolormesh((TaskProjCompareTasks), edgecolors='k', linestyle='-',linewidth=2,vmin=-1,vmax=1,cmap='bwr',shading='flat')\n",
    "\n",
    "#plt.savefig(\"TaskIntersectionPermuteTPRestrict.png\", bbox_inches='tight')\n",
    "axes[1].tick_params(left = False, right = False , labelleft = False , \n",
    "                labelbottom = False, bottom = False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskProjCompareTasks=np.zeros([7,7])\n",
    "\n",
    "#import seaborn as sns\n",
    "from scipy import stats\n",
    "num_tasks=tasks.shape[0]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(5* 2 , 5))\n",
    "\n",
    "for taskID, task in enumerate(tasks):\n",
    "    threshUpper= np.percentile(left_brain[:,task], 75, axis=0)\n",
    "    \n",
    "    pos_index=left_brain[:,task]>threshUpper\n",
    "    neg_index=left_brain[:,task]<threshUpper\n",
    "\n",
    "    for taskID2, task2 in enumerate(tasks):\n",
    "        predtask=LKPredAllTasks[neg_index, taskID]*-1\n",
    "        predtask2=LKPredAllTasks[neg_index, taskID2]*-1\n",
    "        TaskProjCompareTasks[taskID,taskID2]=stats.spearmanr(predtask,predtask2)[0]\n",
    "        \n",
    "TaskProjCompareTasks=TaskProjCompareTasks[::-1,:]\n",
    "axes[0].pcolormesh((TaskProjCompareTasks), edgecolors='k', linestyle=':',linewidth=2,vmin=-1,vmax=1,cmap='bwr')\n",
    "\n",
    "axes[0].tick_params(left = False, right = False , labelleft = False , \n",
    "                labelbottom = False, bottom = False)\n",
    "\n",
    "plt.savefig('PredSimilarityAcrossTasks.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('LKPredAllTasksPos',LKPredAllTasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae118816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuromaps import datasets\n",
    "from neuromaps.datasets import available_annotations,fetch_annotation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fslr = datasets.fetch_atlas(atlas='fslr', density='32k')\n",
    "print(fslr.keys())\n",
    "\n",
    "import nibabel as nib\n",
    "lsphere, rsphere = fslr['sphere']\n",
    "#lsphere, rsphere = fslr['midthickness']\n",
    "lvert, ltri = nib.load(lsphere).agg_data()\n",
    "print(lvert.shape, ltri.shape)\n",
    "\n",
    "fcgradient=np.zeros([lvert.shape[0],10])\n",
    "\n",
    "for i in range(10):\n",
    "    grad_name='fcgradient'+ str(i+1).zfill(2)\n",
    "    annotation = fetch_annotation(source='margulies2016',hemi='L',den='32k',desc=grad_name,return_single=True)\n",
    "    fcgradient[:,i]=nib.load(annotation).agg_data()\n",
    "\n",
    "\n",
    "CorrelationGradToTask=np.zeros([7,3])\n",
    "CorrelationGradToPrediction=np.zeros([7,3])\n",
    "CorrelationGradToOverlap=np.zeros([10])\n",
    "\n",
    "\n",
    "for taskID, task in enumerate(tasks):\n",
    "    threshUpper= np.percentile(left_brain[:,task], 75, axis=0)\n",
    "    pos_index=left_brain[:,task]>threshUpper\n",
    "    neg_index=left_brain[:,task]<threshUpper\n",
    "\n",
    "    for grad in range(3):\n",
    "        CorrelationGradToTask[taskID,grad]=stats.spearmanr(fcgradient[:,grad],left_brain[:,task])[0]\n",
    "        CorrelationGradToPrediction[taskID,grad]=stats.spearmanr(fcgradient[pos_index,grad],LKPredAllTasks[pos_index,taskID])[0]\n",
    "        \n",
    "for grad in range(10):\n",
    "\n",
    "    CorrelationGradToOverlap[grad]=stats.spearmanr(TPProj_NoMedialWall[np.abs(fcgradient[:,grad])>0],fcgradient[np.abs(fcgradient[:,grad])>0,grad])[0]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6687f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "Y = TPProj_NoMedialWall[np.abs(fcgradient[:,grad])>0]\n",
    "X = fcgradient[np.abs(fcgradient[:,grad])>0,:10]\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y,X)\n",
    "\n",
    "results = model.fit()\n",
    "#results.tvalues\n",
    "results.params\n",
    "\n",
    "\n",
    "CorrelationGradToOverlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(TaskProjCompareTasks.flatten()[TaskProjCompareTasks.flatten()<0.99999],differences.flatten()[TaskProjCompareTasks.flatten()<0.99999])\n",
    "\n",
    "stats.pearsonr(TaskProjCompareTasks.flatten()[TaskProjCompareTasks.flatten()<0.99999],differences.flatten()[TaskProjCompareTasks.flatten()<0.99999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250323db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "YeoNetworks=np.zeros([left_brain.shape[0],7])\n",
    "for i in range(7):\n",
    "    cifti = nb.load('Yeo/7Networks' + str(i+1) + '.dscalar.nii')\n",
    "    cifti_data = cifti.get_fdata(dtype=np.float32)\n",
    "    cifti_hdr = cifti.header\n",
    "    nifti_hdr = cifti.nifti_header\n",
    "    axes = [cifti_hdr.get_axis(i) for i in range(cifti.ndim)]\n",
    "    left_brainYeo=surf_data_from_cifti(cifti_data, axes[1], 'CIFTI_STRUCTURE_CORTEX_LEFT')\n",
    "    #left_brainYeoDMN=surf_data_from_cifti(cifti_data, axes[1], 'CIFTI_STRUCTURE_CORTEX_RIGHT')\n",
    "    YeoNetworks[:,i]=left_brainYeo[:,0]\n",
    "\n",
    "realProjYeo = np.zeros([7])\n",
    "# taskToDelete=0\n",
    "# matrix=differences.copy()\n",
    "# matrix = np.delete(matrix, taskToDelete, axis=0)\n",
    "# matrix = np.delete(matrix, taskToDelete, axis=1)\n",
    "# plt.imshow(matrix,cmap='bwr',vmin=-0.5,vmax=0.5)\n",
    "# plt.colorbar()\n",
    "                    \n",
    "#plt.scatter(TPProj_NoMedialWall[np.abs(fcgradient[:,0])>0],TPReal_NoMedialWall[np.abs(fcgradient[:,0])>0])\n",
    "for yn in range(7):\n",
    "    realProjYeo[yn]=stats.spearmanr(TPProj_NoMedialWall[YeoNetworks[:,yn]==1],TPReal_NoMedialWall[YeoNetworks[:,yn]==1])[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_plyRGB(filename, vertices, faces, colorsR,colorsG,colorsB,comment=None):\n",
    "    import pandas as pd\n",
    "    print(\"writing ply format\")\n",
    "    # infer number of vertices and faces\n",
    "    number_vertices = vertices.shape[0]\n",
    "    number_faces = faces.shape[0]\n",
    "    # make header dataframe\n",
    "    header = ['ply',\n",
    "            'format ascii 1.0',\n",
    "            'comment %s' % comment,\n",
    "            'element vertex %i' % number_vertices,\n",
    "            'property float x',\n",
    "            'property float y',\n",
    "            'property float z',\n",
    "            'property uchar red',\n",
    "            'property uchar green',\n",
    "            'property uchar blue',\n",
    "            'element face %i' % number_faces,\n",
    "            'property list uchar int vertex_indices',\n",
    "            'end_header'\n",
    "             ]\n",
    "    header_df = pd.DataFrame(header)\n",
    "    # make dataframe from vertices\n",
    "    vertex_df = pd.DataFrame(vertices/50)\n",
    "    #colors_df = pd.DataFrame(np.tile(np.round(colors/7*255), (3,1)).T)\n",
    "    ColorsR_df=pd.DataFrame(colorsR)\n",
    "    ColorsG_df=pd.DataFrame(colorsG)\n",
    "    ColorsB_df=pd.DataFrame(colorsB)\n",
    "    colorsConcat = pd.concat([ColorsR_df,ColorsG_df,ColorsB_df], axis=1)\n",
    "    colors_df=pd.DataFrame(colorsConcat)\n",
    "    colors_df=colorsConcat.astype(int)\n",
    "    df_concat = pd.concat([vertex_df, colors_df], axis=1)\n",
    "    # make dataframe from faces, adding first row of 3s (indicating triangles)\n",
    "    triangles = np.reshape(3 * (np.ones(number_faces)), (number_faces, 1))\n",
    "    triangles = triangles.astype(int)\n",
    "    faces = faces.astype(int)\n",
    "    faces_df = pd.DataFrame(np.concatenate((triangles, faces), axis=1))\n",
    "    # write dfs to csv\n",
    "    header_df.to_csv(filename, header=None, index=False)\n",
    "    with open(filename, 'a') as f:\n",
    "        df_concat.to_csv(f, header=False, index=False,\n",
    "                         float_format='%.3f', sep=' ')\n",
    "    with open(filename, 'a') as f:\n",
    "        faces_df.to_csv(f, header=False, index=False,\n",
    "                        float_format='%.0f', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.cm\n",
    "cmap = matplotlib.cm.get_cmap('Reds')\n",
    "\n",
    "\n",
    "\n",
    "vertices=gifti_img_Midthickness.darrays[0].data\n",
    "faces=gifti_img_Midthickness.darrays[1].data\n",
    "colors=TPProj_NoMedialWall#/7#*254+1\n",
    "CMap=cmap(colors)*255\n",
    "print(CMap)\n",
    "\n",
    "write_plyRGB('TPProj.ply',vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    "\n",
    "vertices=gifti_img_Midthickness.darrays[0].data\n",
    "faces=gifti_img_Midthickness.darrays[1].data\n",
    "colors=TPReal_NoMedialWall#/7#*254+1\n",
    "CMap=cmap(colors)*255\n",
    "\n",
    "\n",
    "write_plyRGB('TPReal.ply',vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('coolwarm')\n",
    "vertices=gifti_img_Midthickness.darrays[0].data\n",
    "faces=gifti_img_Midthickness.darrays[1].data\n",
    "colors=TPReal_NoMedialWall-TPProj_NoMedialWall#/7#*254+1\n",
    "norm = matplotlib.colors.Normalize(vmin=-1, vmax=1)\n",
    "CMap=cmap(norm(colors))*255\n",
    "\n",
    "\n",
    "write_plyRGB('TPDiff.ply',vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap = matplotlib.cm.get_cmap('coolwarm_r')\n",
    "\n",
    "for i, task in enumerate(tasks):\n",
    "    vertices=gifti_img_Midthickness.darrays[0].data\n",
    "    faces=gifti_img_Midthickness.darrays[1].data    \n",
    "    print(task)\n",
    "    print(taskNames[task])\n",
    "    \n",
    "    colors=left_brain[:,task]\n",
    "    #tempColors=np.where(TPReal==0,0,colors)\n",
    "    norm = matplotlib.colors.Normalize(vmin=-20, vmax=20)\n",
    "    CMap=cmap(norm(colors))*255\n",
    "    PlyFileName='TPTaskActivity' + taskNames[task] + '.ply'\n",
    "    write_plyRGB(PlyFileName,vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    " \n",
    "    colors=np.zeros(left_brain[:,task].shape)\n",
    "    colors[left_brain[:,task]>AllThresh[i]]=left_brain[left_brain[:,task]>AllThresh[i],task]\n",
    "    norm = matplotlib.colors.Normalize(vmin=-20, vmax=20)\n",
    "    CMap=cmap(norm(colors))*255\n",
    "    PlyFileName='TPThresholded' + taskNames[task] + '.ply'\n",
    "    write_plyRGB(PlyFileName,vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    "\n",
    "    \n",
    "    tempColors=np.where(left_brain[:,task]==0,0,LKPredAllTasks[:,i])\n",
    "    #colors=LKPredAllTasks[:,i]\n",
    "    colors=tempColors.copy()\n",
    "    norm = matplotlib.colors.Normalize(vmin=-20, vmax=20)\n",
    "    CMap=cmap(norm(colors))*255\n",
    "    PlyFileName='TPProjected' + taskNames[task] + '.ply'\n",
    "    write_plyRGB(PlyFileName,vertices,faces,CMap[:,0],CMap[:,1],CMap[:,2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d02ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('white') \n",
    "\n",
    "def customize_plot(ax,s_r):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set(xlabel=None)\n",
    "    ax.set(ylabel=None)\n",
    "    ax.set_title(f\"Correlation = {s_r}\")\n",
    "    #ax.spines['top'].set_visible(False)\n",
    "    #ax.spines['right'].set_visible(False)\n",
    "    #ax.spines['bottom'].set_visible(False)\n",
    "    #ax.spines['left'].set_visible(False)\n",
    "    ax.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "    ax.axvline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "fig, axes = plt.subplots(1, num_tasks, figsize=(5.5 * num_tasks, 5))\n",
    "count = 0\n",
    "for taskID, task in enumerate(tasks):\n",
    "    ax = axes[count]\n",
    "\n",
    "    threshUpper = np.percentile(left_brain[:, task], 75, axis=0)\n",
    "    pos_index = left_brain[:, task] > threshUpper\n",
    "    neg_index = left_brain[:, task] < threshUpper\n",
    "\n",
    "    \n",
    "    clust_data = np.ravel(LKPredAllTasks[neg_index, taskID])*-1\n",
    "    task_data = np.ravel(left_brain[neg_index, task])*-1\n",
    "    \n",
    "    \n",
    "    s_r=format(stats.spearmanr(clust_data,task_data)[0], '.2f')\n",
    "    df = pd.DataFrame({\"LKPredAllTasks\": clust_data, \"left_brain\": task_data})\n",
    "    sns.kdeplot(data=df, x=\"LKPredAllTasks\", y=\"left_brain\", fill=True, ax=ax, cmap=\"gray_r\",bw_adjust=0.3,levels=10)\n",
    "\n",
    "    customize_plot(ax,s_r)\n",
    "    count += 1\n",
    "\n",
    "plt.savefig('EachTaskScatterRealPred_lt_75pcPredPos.png')\n",
    "\n",
    "fig2, axes = plt.subplots(1, num_tasks, figsize=(5.5 * num_tasks, 5))\n",
    "count = 0\n",
    "for taskID, task in enumerate(tasks):\n",
    "    ax = axes[count]\n",
    "\n",
    "    neg_index = left_brain[:, task] < 0\n",
    "\n",
    "    clust_data = np.ravel(LKPredAllTasks[neg_index, taskID]) * -1\n",
    "    task_data = np.ravel(left_brain[neg_index, task]) * -1\n",
    "    \n",
    "    s_r=format(stats.spearmanr(clust_data,task_data)[0], '.2f')\n",
    "    df = pd.DataFrame({\"LKPredAllTasks\": clust_data, \"left_brain\": task_data})\n",
    "    sns.kdeplot(data=df, x=\"LKPredAllTasks\", y=\"left_brain\", fill=True, ax=ax, cmap=\"gray_r\",bw_adjust=0.3,levels=10)\n",
    "    \n",
    "    customize_plot(ax,s_r)\n",
    "    count += 1\n",
    "\n",
    "plt.savefig('EachTaskScatterRealPred_ltPrePos_0.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e55aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03fd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "\n",
    "num_tasks=tasks.shape[0]\n",
    "fig, axes = plt.subplots(1,num_tasks, figsize=(5.5* num_tasks , 5))\n",
    "count=0\n",
    "for i in range(len(tasks)):\n",
    "    ax = axes[count]\n",
    "    taskID=i\n",
    "    task=tasks[taskID]\n",
    "    threshUpper= np.percentile(left_brain[:,task], 75, axis=0)\n",
    "    threshLower= np.percentile(left_brain[:,task], 25, axis=0)\n",
    "    pos_index=left_brain[:,task]>threshUpper\n",
    "    dist = DistanceMetric.get_metric('haversine')\n",
    "\n",
    "    DistsExt=dist.pairwise(ptsnew[pos_index,4:6],ptsnew[pos_index==False,4:6])\n",
    "    #DistsInt=dist.pairwise(ptsnew[pos_index,4:6])\n",
    "    MinDistsExt=DistsExt.min(axis=0)\n",
    "    sns.kdeplot(data=MinDistsExt,ax=ax,fill=True,cmap=\"gray_r\")\n",
    "    ax.set_xlim(xmin=0, xmax=0.6)\n",
    "    ax.set_ylim(ymin=0, ymax=4.5)\n",
    "    #ax.set_xlabel(\"Min distance\")\n",
    "    #ax.set_ylabel(\"Count\")\n",
    "    #ax.set_title(f\"Task {taskNames[tasks[taskID]]}\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set(xlabel=None)\n",
    "    ax.set(ylabel=None)\n",
    "\n",
    "    count=count+1\n",
    "\n",
    "plt.savefig('EachTaskMinDistToPostThresh_PredPos.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba081690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "\n",
    "num_tasks=tasks.shape[0]\n",
    "fig, axes = plt.subplots(1,num_tasks, figsize=(5.5* num_tasks , 5))\n",
    "count=0\n",
    "for i in range(len(tasks)):\n",
    "    ax = axes[count]\n",
    "    taskID=i\n",
    "    task=tasks[taskID]\n",
    "    threshUpper= np.percentile(left_brain[:,task], 75, axis=0)\n",
    "    threshLower= np.percentile(left_brain[:,task], 25, axis=0)\n",
    "    pos_index=left_brain[:,task]>threshUpper\n",
    "    dist = DistanceMetric.get_metric('haversine')\n",
    "\n",
    "    DistsExt=dist.pairwise(ptsnew[pos_index,4:6],ptsnew[pos_index==False,4:6])\n",
    "    #DistsInt=dist.pairwise(ptsnew[pos_index,4:6])\n",
    "    MinDistsExt=DistsExt.min(axis=0)\n",
    "\n",
    "    count=count+1\n",
    "\n",
    "plt.savefig('EachTaskMinDistToPostThresh_PredPos.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
